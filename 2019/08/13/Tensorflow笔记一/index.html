<!DOCTYPE html>





<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    save_scroll: false,
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    }
  };
</script>

  <meta name="description" content="概述 mooc 北京大学曹健老师课程：tensorflow笔记 第三节 Tensorflow框架 要点记录 版本：python(3.6.6)， tensorflow(1.3.0)  几个概念基于TensorFlow的NN： 用张量表示数据，用计算图搭建神经网络，用回话执行计算图，优化线上的权重（参数），得到模型。 张量(tensor)：多维数组(列表) 张量的维数称为阶 0阶张量称为标量(s">
<meta name="keywords" content="人工智能,深度学习,Tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow笔记一">
<meta property="og:url" content="https://brandonvno.github.io/2019/08/13/Tensorflow笔记一/index.html">
<meta property="og:site_name" content="Brandon电台">
<meta property="og:description" content="概述 mooc 北京大学曹健老师课程：tensorflow笔记 第三节 Tensorflow框架 要点记录 版本：python(3.6.6)， tensorflow(1.3.0)  几个概念基于TensorFlow的NN： 用张量表示数据，用计算图搭建神经网络，用回话执行计算图，优化线上的权重（参数），得到模型。 张量(tensor)：多维数组(列表) 张量的维数称为阶 0阶张量称为标量(s">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://brandonvno.github.io/uploads/tensorflow_notes/image1.png">
<meta property="og:image" content="https://brandonvno.github.io/uploads/tensorflow_notes/image2.png">
<meta property="og:updated_time" content="2019-08-27T01:56:11.446Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow笔记一">
<meta name="twitter:description" content="概述 mooc 北京大学曹健老师课程：tensorflow笔记 第三节 Tensorflow框架 要点记录 版本：python(3.6.6)， tensorflow(1.3.0)  几个概念基于TensorFlow的NN： 用张量表示数据，用计算图搭建神经网络，用回话执行计算图，优化线上的权重（参数），得到模型。 张量(tensor)：多维数组(列表) 张量的维数称为阶 0阶张量称为标量(s">
<meta name="twitter:image" content="https://brandonvno.github.io/uploads/tensorflow_notes/image1.png">
  <link rel="alternate" href="/atom.xml" title="Brandon电台" type="application/atom+xml">
  <link rel="canonical" href="https://brandonvno.github.io/2019/08/13/Tensorflow笔记一/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Tensorflow笔记一 | Brandon电台</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ac76ceae447ceffbc8058af5886fbe8d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  <div class="container sidebar-position-left">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Brandon电台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">好记性不如烂笔头</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>


    </div>
</nav>
</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content page-post-detail">
            

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://brandonvno.github.io/2019/08/13/Tensorflow笔记一/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Brandon">
      <meta itemprop="description" content="编程、经验、感悟、读后感的一点记录和分享">
      <meta itemprop="image" content="/uploads/Avata1.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Brandon电台">
    </span>
      <header class="post-header">

        
          <h1 class="post-title" itemprop="name headline">Tensorflow笔记一

              
            
          </h1>
        

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-08-13 18:47:21" itemprop="dateCreated datePublished" datetime="2019-08-13T18:47:21+08:00">2019-08-13</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-08-27 09:56:11" itemprop="dateModified" datetime="2019-08-27T09:56:11+08:00">2019-08-27</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/" itemprop="url" rel="index"><span itemprop="name">人工智能</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/机器学习/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
              
            </span>
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon"
              >
                <i class="fa fa-eye"></i>
                 阅读次数： 
                <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
              </span>
            </span>
          <br>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>


<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p> mooc 北京大学曹健老师课程：tensorflow笔记 第三节 Tensorflow框架 要点记录<br> 版本：python(3.6.6)， tensorflow(1.3.0)</p>
<hr>
<h2 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h2><h3 id="基于TensorFlow的NN："><a href="#基于TensorFlow的NN：" class="headerlink" title="基于TensorFlow的NN："></a>基于TensorFlow的NN：</h3><p> 用张量表示数据，用计算图搭建神经网络，用回话执行计算图，优化线上的权重（参数），得到模型。</p>
<h3 id="张量-tensor-：多维数组-列表"><a href="#张量-tensor-：多维数组-列表" class="headerlink" title="张量(tensor)：多维数组(列表)"></a>张量(tensor)：多维数组(列表)</h3><p> 张量的维数称为<strong>阶</strong><br> 0阶张量称为标量(scalar)，如123<br> 1阶张量称为向量(vector)<br> 2阶张量称为矩阵(matrix)<br> 张量可以表示0阶到n阶数组</p>
<h3 id="计算图-Graph-："><a href="#计算图-Graph-：" class="headerlink" title="计算图(Graph)："></a>计算图(Graph)：</h3><p> 搭建神经网络的计算过程，只搭建，不计算</p>
<h3 id="会话-Session-："><a href="#会话-Session-：" class="headerlink" title="会话(Session)："></a>会话(Session)：</h3><p> 执行计算图中的节点运算<br> 用python实现计算的语法：<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with tensorflow.Session() as sess:</span><br><span class="line">   print(sess.run(y))</span><br></pre></td></tr></table></figure></p>
<h3 id="参数：是指神经元线上的权重，用标量表示，随机赋给初值"><a href="#参数：是指神经元线上的权重，用标量表示，随机赋给初值" class="headerlink" title="参数：是指神经元线上的权重，用标量表示，随机赋给初值"></a>参数：是指神经元线上的权重，用标量表示，随机赋给初值</h3><p> 随机赋值举例：<br> <code>w = tf.Variable(tf.randon_normal([2,3], stddev = 2, mean = 0, seed = 1))</code><br> random_normal表示正态分布，stddev是标准差，mean是平均值， seed是随机种子。<br> 标准差，平均值，随机种子可不写，随机种子不写每次随机的值都不一样。</p>
<p> 另外几个常用方法：<br> <code>tf.truncated_normal()</code><br> 去掉过大偏离点的正态分布（随机出来的值与平均值差距超过两个标准差，则舍弃）<br> <code>tf.random_uniform()</code><br> 平均分布<br> <code>tf.zeros()</code><br> 生成全0数组，如tf.zeros([3,2], int32)<br> <code>tf.ones()</code><br> 生成全1数组，如tf.ones([3,2], int32)<br> <code>tf.fill()</code><br> 生成定值数组，如tf.fill([3,2], 6)<br> <code>tf.constant()</code><br> 生成指定数组</p>
<hr>
<h2 id="神经网络实现过程"><a href="#神经网络实现过程" class="headerlink" title="神经网络实现过程"></a>神经网络实现过程</h2><ol>
<li>准备数据集，提取特征，作为输入喂给神经网络（Neural Network，NN）</li>
<li>搭建NN结构，从输入到输出（先搭建计算图，再用会话执行）<br>（NN前向传播算法 -&gt; 计算输出）</li>
<li>大量特征数据喂给NN，迭代优化NN参数<br>（NN反向传播算法 -&gt; 优化参数训练模型）</li>
<li>使用训练好的模型预测和分类</li>
</ol>
<hr>
<h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h2><p> 示例：<br> <img src="/uploads/tensorflow_notes/image1.png" alt="&quot;示例&quot;" title="前向传播讲解示例"><br> 推导：<br> <img src="/uploads/tensorflow_notes/image2.png" alt="&quot;推导&quot;" title="前向传播示例推导"><br> W矩阵，前面有m个节点，后面有n个节点，则为mXn阶矩阵。<br> 输入不计入神经网络层，a层是第一个计算层，也是神经网络的第一层，这里是1X3阶矩阵</p>
<p> 说明：</p>
<ul>
<li><p>变量初始化、计算图节点运算都要使用会话（with结构）实现<br><code>with tf.Session() as sess</code></p>
</li>
<li><p>变量初始化<br><code>init_op = tf.global_variables_initializer()</code><br><code>sess.run(init_op)</code></p>
</li>
<li><p>计算图节点运算: sess.run()中写入带运算节点<br><code>sess.run(y)</code></p>
</li>
<li><p>给神经网络喂数据：用tf.placeholder占位，在sess.run()中使用feed_dict喂数据<br>喂一组数据：<br><code>x = tf.placeholder(tf.float32, shape=(1,2))</code><br><code>sess.run(y, feed_dict={x:[[0.5, 0.6]]}</code></p>
<p>喂多组数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.placeholder(tf.float32, shape=(None, 2))</span><br><span class="line">sess.run(y, feed_dict=&#123;x:[[0.1, 0.2], [0.2, 0.3], [0.3, 0.4]]&#125;)</span><br></pre></td></tr></table></figure>

<p>shape第二个参数是模型的特征数，比如此模型有重量和体积两个特征，故为2。</p>
</li>
</ul>
<p>代码示例1：<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> #coding:utf-8</span><br><span class="line">#两层简单神经网络</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">#定义输入和参数</span><br><span class="line">x = tf.constant([[0.7, 0.5]])</span><br><span class="line">w1 = tf.Variable(tf.random_normal([2,3], stddev = 1, seed=1))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([3,1], stddev = 1, seed = 1))</span><br><span class="line"></span><br><span class="line">#定义前向传播过程</span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line">#用会话计算结果</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    print(&quot;result y in this file is:\n&quot;, sess.run(y))</span><br></pre></td></tr></table></figure></p>
<p>代码示例2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#coding:utf-8</span><br><span class="line">#两层简单神经网络</span><br><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">#定义输入和参数</span><br><span class="line">#用placeholder实现输入定义</span><br><span class="line">x = tf.placeholder(tf.float32, shape=(1,2))</span><br><span class="line">w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed = 1))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed = 1))</span><br><span class="line"></span><br><span class="line">#定义前向传播过程</span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line">#用会话计算结果</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    print(&quot;y in this file is:\n&quot;, sess.run(y, feed_dict = &#123;x:[[0.7, 0.5]]&#125;))</span><br></pre></td></tr></table></figure>

<p>代码示例3：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#coding:utf-8</span><br><span class="line">#两层简单神经网络(喂多组数据)</span><br><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">#定义输入和参数</span><br><span class="line">#用placeholder定义输入(sess.run()喂多组数据)</span><br><span class="line">x = tf.placeholder(tf.float32, shape=(None, 2))</span><br><span class="line">w1 = tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))</span><br><span class="line"></span><br><span class="line">#定义前向传播过程</span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line">#调用会话计算结果</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    init_op = tf.global_variables_initializer();</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    print(&quot;y in this file is:\n&quot;, sess.run(y, feed_dict = &#123;x:[[0.7, 0.5],[0.2, 0.3],[0.3, 0.4], [0.4, 0.5]]&#125;))</span><br><span class="line">    print(&quot;w1:\n&quot;, sess.run(w1))</span><br><span class="line">    print(&quot;w1:\n&quot;, sess.run(w2))</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p> 反向传播是一个不断训练模型参数，在所有参数上使用梯度下降，使NN模型在训练数据上的损失函数最小</p>
<p> 损失函数(loss)：预测值(y)与已知答案(y_)的差距。 均方误差MSE是计算损失函数的一种方法</p>
<p> 均方误差MSE：MSE(y_, y) = \(\frac{\sum_{i=1}^{n}(y-y\_)^{2}}{n}\)</p>
<p> 均方误差计算损失函数代码：<br> <code>loss = tf.reduce_mean(tf.square(y-y_))</code><br> 其中y和y_都是张量</p>
<p> 反向传播的训练方法：以减小loss值为优化目标<br> 三种训练方法：<br> <code>train_step = tf.train.GiadientDescentOptimizer(learning_rate).minimize(loss)</code><br> <code>train_step = tr.train.MomentumOptimizer(learning_rate, momentum).minimize(loss)</code><br> <code>train_step = tr.train.AdamOptimizer(learning_rate),minimize(loss)</code><br> learning_rate是指学习率，它决定每次更新的幅度，一开始可以选一个较小值，比如0.001</p>
<p> 反向传播代码示例：<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">#coding:utf_8</span><br><span class="line">#反向传播过程实例</span><br><span class="line">#导入模块，生成模拟数据集</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line">BATCH_SIZE = 8</span><br><span class="line">seed = 23455</span><br><span class="line"></span><br><span class="line">#基于seed生成随机数</span><br><span class="line">rng = np.random.RandomState(seed)</span><br><span class="line">#随机数返回32行2列的矩阵 表示32组 体积和重量 作为输入数据集</span><br><span class="line">X = rng.rand(32, 2)</span><br><span class="line">#从X这个32行2列的矩阵中 取出一行 判断如果和小于1 给Y赋值1 如该和不小于1 给Y赋值0 作为输入数据集的标签</span><br><span class="line">Y = [[int(x0 + x1 &lt;1)] for (x0, x1) in X]</span><br><span class="line">print(&quot;X:\n&quot;, X)</span><br><span class="line">print(&quot;Y:\n&quot;, Y)</span><br><span class="line"></span><br><span class="line">#定义神经网络的输入</span><br><span class="line">x = tf.placeholder(tf.float32, shape=(None, 2))</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=(None, 1))</span><br><span class="line"></span><br><span class="line">#定义神经网络的参数</span><br><span class="line">w1 = tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))</span><br><span class="line"></span><br><span class="line">#定义神经网络前向传播过程</span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line">#定义损失函数</span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_))</span><br><span class="line">#三种反向传播方法</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)</span><br><span class="line">#train_step = tf.train.MomentumOptimizer(0.001, 0.9).minimize(loss)</span><br><span class="line">#train_step = tf.train.AdamOptimizer(0.001).minimize(loss)</span><br><span class="line"></span><br><span class="line">#生成会话，训练STEPS轮</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    #输出当前（未经训练）的参数取值</span><br><span class="line">    print(&quot;w1:\n&quot;, sess.run(w1))</span><br><span class="line">    print(&quot;w2:\n&quot;, sess.run(w2))</span><br><span class="line">    print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">    #训练模型</span><br><span class="line">    STEPS = 3000</span><br><span class="line">    for i in range(STEPS):</span><br><span class="line">        start = (i*BATCH_SIZE) %32</span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict=&#123;x:X[start:end], y_:Y[start:end]&#125;)</span><br><span class="line">        if i%500 == 0:</span><br><span class="line">            total_loss = sess.run(loss, feed_dict=&#123;x:X, y_:Y&#125;)</span><br><span class="line">            print(&quot;After %d training steps, loss on all data is %g&quot;%(i, total_loss))</span><br><span class="line">    #输出训练后的参数取值</span><br><span class="line">    print(&quot;\n&quot;)</span><br><span class="line">    print(&quot;w1:\n&quot;, sess.run(w1))</span><br><span class="line">    print(&quot;w2:\n&quot;, sess.run(w2))</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="搭建神经网络的八股：准备、前向传播、反向传播、迭代"><a href="#搭建神经网络的八股：准备、前向传播、反向传播、迭代" class="headerlink" title="搭建神经网络的八股：准备、前向传播、反向传播、迭代"></a>搭建神经网络的八股：准备、前向传播、反向传播、迭代</h2><ul>
<li><p>准备<br>import 相关模块、 定义常量、 生成数据集</p>
</li>
<li><p>前向传播<br>定义输入：特征输入x，标准答案y_<br>定义参数：（一般是随机）定义第一层网络参数w1和第二程网络参数w2<br>定义输出：定义计算图(Graph)，即定义第一层网络a和结果y的计算过程</p>
</li>
<li><p>反向传播<br>定义损失函数：loss<br>定义反向传播方法：train_step</p>
</li>
<li><p>迭代：生成会话(Session)，训练STEPS轮</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">with tf.Session() as sess</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess_run(init_op)</span><br><span class="line">    </span><br><span class="line">    STEPS = 3000</span><br><span class="line">    for i in range(STEPS):</span><br><span class="line">        start = </span><br><span class="line">        end = </span><br><span class="line">        sess.run(train_step, feed_dict=)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<hr>

    </div>

    
    
    
    
      <div>
        <div id="reward-container">
  <div>分享是一种快乐，请随意</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.png" alt="Brandon 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

      </div>

    <footer class="post-footer">
          
        
        <div class="post-tags">
            <a href="/tags/人工智能/" rel="tag"># 人工智能</a>
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/Tensorflow/" rel="tag"># Tensorflow</a>
          
        </div>
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
              <a href="/2019/08/06/Unity用IL2Cpp打包64位版本，上线Google商店/" rel="next" title="Unity用IL2Cpp打包64位版本aab文件，上线Google商店">
                <i class="fa fa-chevron-left"></i> Unity用IL2Cpp打包64位版本aab文件，上线Google商店
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
              <a href="/2019/08/14/在markdown中使用数学公式/" rel="prev" title="在markdown中使用数学公式">
                在markdown中使用数学公式 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
    </footer>
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/uploads/Avata1.png"
      alt="Brandon">
  <p class="site-author-name" itemprop="name">Brandon</p>
  <div class="site-description motion-element" itemprop="description">编程、经验、感悟、读后感的一点记录和分享</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/brandonvno" title="GitHub &rarr; https://github.com/brandonvno" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
  </div>


  <div class="links-of-blogroll motion-element links-of-blogroll-block">
    <div class="links-of-blogroll-title">
      <i class="fa  fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.taptap.com/app/63844" title="https://www.taptap.com/app/63844" rel="noopener" target="_blank">行界：重构</a>
        </li>
      
    </ul>
  </div>

        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#概述"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#几个概念"><span class="nav-number">2.</span> <span class="nav-text">几个概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于TensorFlow的NN："><span class="nav-number">2.1.</span> <span class="nav-text">基于TensorFlow的NN：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#张量-tensor-：多维数组-列表"><span class="nav-number">2.2.</span> <span class="nav-text">张量(tensor)：多维数组(列表)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算图-Graph-："><span class="nav-number">2.3.</span> <span class="nav-text">计算图(Graph)：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#会话-Session-："><span class="nav-number">2.4.</span> <span class="nav-text">会话(Session)：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数：是指神经元线上的权重，用标量表示，随机赋给初值"><span class="nav-number">2.5.</span> <span class="nav-text">参数：是指神经元线上的权重，用标量表示，随机赋给初值</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络实现过程"><span class="nav-number">3.</span> <span class="nav-text">神经网络实现过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#前向传播"><span class="nav-number">4.</span> <span class="nav-text">前向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#反向传播"><span class="nav-number">5.</span> <span class="nav-text">反向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#搭建神经网络的八股：准备、前向传播、反向传播、迭代"><span class="nav-number">6.</span> <span class="nav-text">搭建神经网络的八股：准备、前向传播、反向传播、迭代</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Brandon</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

<script src="/js/utils.js?v=7.3.0"></script>
  <script src="/js/motion.js?v=7.3.0"></script>


  <script src="/js/affix.js?v=7.3.0"></script>
  <script src="/js/schemes/pisces.js?v=7.3.0"></script>



<script src="/js/next-boot.js?v=7.3.0"></script>






  















  <script src="/js/local-search.js?v=7.3.0"></script>














  

  

  


  
  <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>


    
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">
<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '37854a8b3b718ee36cda',
    clientSecret: '2c841db056b110a0454e394cd9993cb4026e1c13',
    repo: 'brandonvno.github.io',
    owner: 'brandonvno',
    admin: ['brandonvno'],
    id: md5(location.pathname),
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618},"display":{"superSample":2,"width":200,"height":400,"position":"right","hOffset":0,"vOffset":-20},"react":{"opacityDefault":0.5,"opacityOnHover":0.5,"opacity":0.7},"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
